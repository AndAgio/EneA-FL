{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_number_of_flops(model, batch_size=1):\n",
    "    total_flops = 0\n",
    "    for name, layer in model.named_children():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            total_flops += layer.in_features * layer.out_features * batch_size\n",
    "        elif isinstance(layer, nn.Conv1d):\n",
    "            total_flops += layer.in_channels * layer.out_channels * layer.kernel_size[0] * batch_size\n",
    "        elif isinstance(layer, nn.Conv2d):\n",
    "            total_flops += 2 * layer.in_channels * layer.out_channels * layer.kernel_size[0] * batch_size\n",
    "\n",
    "    return total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FemnistConfig(object):\n",
    "    image_shape = (1, 28, 28)\n",
    "    conv_channels = [32, 64]  # [20, 50]\n",
    "    conv_kernels = [5, 5]  # [3, 3]\n",
    "    conv_strides = [1, 1]\n",
    "    lin_channels = [4*4*64, 2048]  # [5*5*50, 500]\n",
    "    n_classes = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as t_func\n",
    "\n",
    "\n",
    "class FemnistModel(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(FemnistModel, self).__init__()\n",
    "        self.config = FemnistConfig()\n",
    "        # Convolution layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.config.image_shape[0],\n",
    "                               out_channels=self.config.conv_channels[0],\n",
    "                               kernel_size=self.config.conv_kernels[0],\n",
    "                               stride=self.config.conv_strides[0])\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.config.conv_channels[0],\n",
    "                               out_channels=self.config.conv_channels[1],\n",
    "                               kernel_size=self.config.conv_kernels[1],\n",
    "                               stride=self.config.conv_strides[1])\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=self.config.lin_channels[0],\n",
    "                             out_features=self.config.lin_channels[1])\n",
    "        self.fc2 = nn.Linear(in_features=self.config.lin_channels[1],\n",
    "                             out_features=self.config.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = t_func.relu(x)\n",
    "        x = t_func.max_pool2d(x, 2, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = t_func.relu(x)\n",
    "        x = t_func.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.config.lin_channels[0])\n",
    "        x = self.fc1(x)\n",
    "        x = t_func.relu(x)\n",
    "        return t_func.softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentConfig(object):\n",
    "    embs_file = 'enea_fl/models/embs.json'\n",
    "    cnn_num_channels = 100\n",
    "    cnn_kernel_size = [3, 4, 5]\n",
    "    lstm_layers = 2\n",
    "    lstm_hidden = 20\n",
    "    lstm_bidirectional = False\n",
    "    output_size = 2\n",
    "    max_sen_len = 30\n",
    "    dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as t_func\n",
    "\n",
    "\n",
    "class CnnSent(nn.Module):\n",
    "    def __init__(self, embs=None):\n",
    "        super(CnnSent, self).__init__()\n",
    "        self.config = SentConfig()\n",
    "        if embs is None:\n",
    "            try:\n",
    "                print(\"Loading GloVe embeddings [{}]...\".format(self.config.embs_file))\n",
    "                with open(self.config.embs_file, 'r') as inf:\n",
    "                    embs = json.load(inf)\n",
    "            except FileNotFoundError:\n",
    "                _ = subprocess.call(\"./enea_fl/models/get_embs.sh\", shell=True)\n",
    "                with open(self.config.embs_file, 'r') as inf:\n",
    "                    embs = json.load(inf)\n",
    "        self.embs = embs\n",
    "        print(\"Loaded GloVe embeddings.\")\n",
    "        vocab = self.embs['vocab']\n",
    "        vocab_size = len(vocab)\n",
    "        print(\"Vocab size: {}\".format(vocab_size))\n",
    "        word_embeddings = torch.from_numpy(np.array(self.embs['emba'])).type(torch.FloatTensor)\n",
    "        word_embeddings_size = word_embeddings.shape[1]\n",
    "        # Embedding Layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, word_embeddings_size)\n",
    "        self.embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
    "        # Convolution Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=word_embeddings_size, out_channels=self.config.cnn_num_channels,\n",
    "                               kernel_size=self.config.cnn_kernel_size[0])\n",
    "        self.kernel_size1 = self.config.max_sen_len - self.config.cnn_kernel_size[0] + 1\n",
    "        self.conv2 = nn.Conv1d(in_channels=word_embeddings_size, out_channels=self.config.cnn_num_channels,\n",
    "                               kernel_size=self.config.cnn_kernel_size[1])\n",
    "        self.kernel_size2 = self.config.max_sen_len - self.config.cnn_kernel_size[1] + 1\n",
    "        self.conv3 = nn.Conv1d(in_channels=word_embeddings_size, out_channels=self.config.cnn_num_channels,\n",
    "                               kernel_size=self.config.cnn_kernel_size[2])\n",
    "        self.kernel_size3 = self.config.max_sen_len - self.config.cnn_kernel_size[2] + 1\n",
    "        self.dropout = nn.Dropout(self.config.dropout)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.config.cnn_num_channels * len(self.config.cnn_kernel_size), self.config.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed input to GloVe embeddings\n",
    "        embedded_sent = self.embeddings(x)\n",
    "        embedded_sent = embedded_sent.permute(1, 2, 0)\n",
    "        # First convolution\n",
    "        out1 = t_func.max_pool1d(t_func.relu(self.conv1(embedded_sent)), kernel_size=self.kernel_size1).squeeze(2)\n",
    "        # Second convolution\n",
    "        out2 = t_func.max_pool1d(t_func.relu(self.conv2(embedded_sent)), kernel_size=self.kernel_size3).squeeze(2)\n",
    "        # Third convolution\n",
    "        out3 = t_func.max_pool1d(t_func.relu(self.conv3(embedded_sent)), kernel_size=self.kernel_size3).squeeze(2)\n",
    "        # Aggregate convolutions\n",
    "        all_out = torch.cat((out1, out2, out3), 1)\n",
    "        # Fully connected and output\n",
    "        final_feature_map = self.dropout(all_out)\n",
    "        return t_func.softmax(self.fc(final_feature_map), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nbaiot(nn.Module):\n",
    "    def __init__(self, input_shape=31, nb_classes=11):\n",
    "        super(Nbaiot, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(32, nb_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2244928"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_number_of_flops(FemnistModel(), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings [enea_fl/models/embs.json]...\n",
      "Loaded GloVe embeddings.\n",
      "Vocab size: 400000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60600"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_number_of_flops(CnnSent(), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Total params: 2278334\n",
      "Total MACs: 5.962M\n",
      "Total FLOPs: 2.278M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "model = FemnistModel()\n",
    "input = torch.randn(1, 1, 28, 28)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total params: {}\".format(total_params))\n",
    "print(\"Total MACs: {}\".format(macs))\n",
    "print(\"Total FLOPs: {}\".format(params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings [enea_fl/models/embs.json]...\n",
      "Loaded GloVe embeddings.\n",
      "Vocab size: 400000\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Total params: 20060952\n",
      "Total MACs: 16.106M\n",
      "Total FLOPs: 60.902K\n"
     ]
    }
   ],
   "source": [
    "model = CnnSent()\n",
    "input = torch.randint(0, 100, (30 ,10))\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total params: {}\".format(total_params))\n",
    "print(\"Total MACs: {}\".format(macs))\n",
    "print(\"Total FLOPs: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "Total params: 4491\n",
      "Total MACs: 4.384K\n",
      "Total FLOPs: 4.491K\n"
     ]
    }
   ],
   "source": [
    "model = Nbaiot()\n",
    "input = torch.randn(1,1,31)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total params: {}\".format(total_params))\n",
    "print(\"Total MACs: {}\".format(macs))\n",
    "print(\"Total FLOPs: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eneaFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
