#### FLOPS per WATT computation

To compute the FLOPS per watt for the given ML model, you need to estimate the number of floating-point operations (FLOPS) performed by the model and measure its power consumption. Here's a step-by-step guide on how to proceed:

Step 1: Identify the computational components:
Review the model architecture and identify the specific computational components that contribute to the FLOPS count. In this case, you need to focus on the convolutional layers and the fully connected layer since they involve most of the floating-point operations.

Step 2: Count the number of floating-point operations:
For each relevant computational component, count the number of floating-point operations it performs. This depends on the specific operations and layer sizes involved. Here's a general approach:

a) Convolutional layers:
Each convolutional layer performs multiple multiplications and additions per output element. The number of FLOPS in a convolutional layer can be estimated as:
```
FLOPS_conv = 2 * out_channels * in_channels * kernel_size * output_size
```
b) Fully connected layer:
The fully connected layer performs matrix multiplication and addition operations. The number of FLOPS in the fully connected layer can be estimated as:
```
FLOPS_fc = 2 * input_size * output_size
```
Sum up the FLOPS from all the relevant components to get the total number of FLOPS for the model.

Step 3: Measure the power consumption:
Use a power meter or power monitoring tools to measure the power consumption of the system while the model is running. Note down the power consumption value in watts.

Step 4: Compute FLOPS per watt:
Divide the total number of FLOPS by the power consumption to obtain the FLOPS per watt value.

It's important to note that the FLOPS count may vary depending on the input size and other factors. Additionally, measuring the power consumption accurately is crucial for obtaining meaningful results.